<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>qwen+Fastapi | You_zip</title><meta name="author" content="Youzipii"><meta name="copyright" content="Youzipii"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="qwen+Fastapi搭建本地知识库参考链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;xiaobing259&#x2F;article&#x2F;details&#x2F;139998673  https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;cu124&#x2F;torch-2.4.1%2Bcu124-cp39-cp39-win_amd64.whl https:&#x2F;&#x2F;pytorch.org&#x2F;get-started&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="qwen+Fastapi">
<meta property="og:url" content="http://example.com/2024/09/28/qwen-Fastapi/index.html">
<meta property="og:site_name" content="You_zip">
<meta property="og:description" content="qwen+Fastapi搭建本地知识库参考链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;xiaobing259&#x2F;article&#x2F;details&#x2F;139998673  https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;cu124&#x2F;torch-2.4.1%2Bcu124-cp39-cp39-win_amd64.whl https:&#x2F;&#x2F;pytorch.org&#x2F;get-started&#x2F;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png">
<meta property="article:published_time" content="2024-09-28T12:03:21.000Z">
<meta property="article:modified_time" content="2024-09-29T15:33:28.725Z">
<meta property="article:author" content="Youzipii">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png"><link rel="shortcut icon" href="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png"><link rel="canonical" href="http://example.com/2024/09/28/qwen-Fastapi/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'qwen+Fastapi',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-29 23:33:28'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/static-butterfly/dist/css/index.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">83</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/image/bk_image/bg3.png')"><nav id="nav"><span id="blog-info"><a href="/" title="You_zip"><span class="site-name">You_zip</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">qwen+Fastapi</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-28T12:03:21.000Z" title="发表于 2024-09-28 20:03:21">2024-09-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-29T15:33:28.725Z" title="更新于 2024-09-29 23:33:28">2024-09-29</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="qwen+Fastapi"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="qwen-Fastapi搭建本地知识库"><a href="#qwen-Fastapi搭建本地知识库" class="headerlink" title="qwen+Fastapi搭建本地知识库"></a>qwen+Fastapi搭建本地知识库</h1><p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xiaobing259/article/details/139998673">https://blog.csdn.net/xiaobing259/article/details/139998673</a></p>
<p> <a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/cu124/torch-2.4.1%2Bcu124-cp39-cp39-win_amd64.whl">https://download.pytorch.org/whl/cu124/torch-2.4.1%2Bcu124-cp39-cp39-win_amd64.whl</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/?spm=a2c6h.12873639.article-detail.13.281c5bdfwUad0k">https://pytorch.org/get-started/previous-versions/?spm=a2c6h.12873639.article-detail.13.281c5bdfwUad0k</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43874102/article/details/123164105?spm=a2c6h.12873639.article-detail.11.281c5bdfwUad0k">https://blog.csdn.net/qq_43874102/article/details/123164105?spm=a2c6h.12873639.article-detail.11.281c5bdfwUad0k</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv35427548/?jump_opus=1">https://www.bilibili.com/read/cv35427548/?jump_opus=1</a></p>
<p>内存不多，用这个qwen&#x2F;Qwen2-7B-Instruct，差不多20G，2.5要百G，没那么多内存。。。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="创建虚环境"><a href="#创建虚环境" class="headerlink" title="创建虚环境"></a>创建虚环境</h3><p>正好前面补充了虚环境的知识，这里我们直接创建一个.qwen的虚环境</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m venv .qwen</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240928221426863.png" alt="image-20240928221426863"></p>
<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><p>下面我们下载一下需要用到的包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install fastapi==0.104.1 uvicorn==0.24.0.post1 requests==2.25.1 modelscope==1.11.0 transformers==4.41.0 streamlit==1.24.0 sentencepiece==0.1.99 accelerate==0.24.1 transformers_stream_generator==0.0.4</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240928221505464.png" alt="image-20240928221505464"></p>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><p>这里用博主给的脚本，稍作修改即可，也可以用官网的教程下载<a target="_blank" rel="noopener" href="https://modelscope.cn/models/Qwen/Qwen2-7B-Instruct/files">https://modelscope.cn/models/Qwen/Qwen2-7B-Instruct/files</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">modelscope download --model Qwen/Qwen2-7B-Instruct</span><br></pre></td></tr></table></figure>

<p>但这个不会把文件保存到当前目录，用脚本可以指定缓存目录<a target="_blank" rel="noopener" href="https://www.onetts.com/wk/12439">使用参考</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line"><span class="comment"># snapshot_download函数用于下载模型</span></span><br><span class="line">model_dir = snapshot_download(</span><br><span class="line">    <span class="string">&#x27;qwen/Qwen2-7B-Instruct&#x27;</span>,  <span class="comment"># 模型名称</span></span><br><span class="line">    cache_dir=<span class="string">&#x27;./autodl-tmp&#x27;</span>,  <span class="comment"># 缓存目录</span></span><br><span class="line">    revision=<span class="string">&#x27;master&#x27;</span>  <span class="comment"># 版本号</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>但不懂为什么下载会停住</p>
<p><img src="/../image/image-20240928222819389.png" alt="image-20240928222819389"></p>
<p>看了下任务管理器，pyton还是有占用网络资源的的</p>
<p><img src="/../image/image-20240928222917899.png" alt="image-20240928222917899"></p>
<p>等了一会，进度条动了，所以遇到这种情况可以等一等，可能是还没显示</p>
<p><img src="/../image/image-20240928223007931.png" alt="image-20240928223007931"></p>
<p>下载好后，大概有个15G左右</p>
<p><img src="/../image/image-20240928233227573.png" alt="image-20240928233227573"></p>
<h2 id="代码准备"><a href="#代码准备" class="headerlink" title="代码准备"></a>代码准备</h2><h3 id="安装fastapi库"><a href="#安装fastapi库" class="headerlink" title="安装fastapi库"></a>安装fastapi库</h3><p><a target="_blank" rel="noopener" href="https://fastapi.org.cn/tutorial/first-steps/">https://fastapi.org.cn/tutorial/first-steps/</a></p>
<p>在<code>./autodl-tmp</code>路径下创建<code>fastapi_Demo.py</code>文件，编写FastAPI应用代码，用于加载模型并提供API服务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding=&quot;utf-8&quot;</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置设备参数</span></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span>  <span class="comment"># 使用CUDA</span></span><br><span class="line">DEVICE_ID = <span class="string">&quot;0&quot;</span>  <span class="comment"># CUDA设备ID，如果未设置则为空</span></span><br><span class="line">CUDA_DEVICE = <span class="string">f&quot;<span class="subst">&#123;DEVICE&#125;</span>:<span class="subst">&#123;DEVICE_ID&#125;</span>&quot;</span> <span class="keyword">if</span> DEVICE_ID <span class="keyword">else</span> DEVICE  <span class="comment"># 组合CUDA设备信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理GPU内存函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">torch_gc</span>():</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  <span class="comment"># 检查是否可用CUDA</span></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.device(CUDA_DEVICE):  <span class="comment"># 指定CUDA设备</span></span><br><span class="line">            torch.cuda.empty_cache()  <span class="comment"># 清空CUDA缓存</span></span><br><span class="line">            torch.cuda.ipc_collect()  <span class="comment"># 收集CUDA内存碎片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FastAPI应用</span></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理POST请求的端点</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">global</span> model, tokenizer  <span class="comment"># 声明全局变量以便在函数内部使用模型和分词器</span></span><br><span class="line">    json_post_raw = <span class="keyword">await</span> request.json()  <span class="comment"># 获取POST请求的JSON数据</span></span><br><span class="line">    json_post = json.dumps(json_post_raw)  <span class="comment"># 将JSON数据转换为字符串</span></span><br><span class="line">    json_post_list = json.loads(json_post)  <span class="comment"># 将字符串转换为Python对象</span></span><br><span class="line">    prompt = json_post_list.get(<span class="string">&#x27;prompt&#x27;</span>)  <span class="comment"># 获取请求中的提示</span></span><br><span class="line"></span><br><span class="line">    messages = [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用模型进行对话生成</span></span><br><span class="line">    input_ids = tokenizer.apply_chat_template(messages,tokenize=<span class="literal">False</span>,add_generation_prompt=<span class="literal">True</span>)</span><br><span class="line">    model_inputs = tokenizer([input_ids], return_tensors=<span class="string">&quot;pt&quot;</span>).to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    generated_ids = model.generate(model_inputs.input_ids,max_new_tokens=<span class="number">512</span>)</span><br><span class="line">    generated_ids = [</span><br><span class="line">        output_ids[<span class="built_in">len</span>(input_ids):] <span class="keyword">for</span> input_ids, output_ids <span class="keyword">in</span> <span class="built_in">zip</span>(model_inputs.input_ids, generated_ids)</span><br><span class="line">    ]</span><br><span class="line">    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">    now = datetime.datetime.now()  <span class="comment"># 获取当前时间</span></span><br><span class="line">    time = now.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)  <span class="comment"># 格式化时间为字符串</span></span><br><span class="line">    <span class="comment"># 构建响应JSON</span></span><br><span class="line">    answer = &#123;</span><br><span class="line">        <span class="string">&quot;response&quot;</span>: response,</span><br><span class="line">        <span class="string">&quot;status&quot;</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">&quot;time&quot;</span>: time</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 构建日志信息</span></span><br><span class="line">    log = <span class="string">&quot;[&quot;</span> + time + <span class="string">&quot;] &quot;</span> + <span class="string">&#x27;&quot;, prompt:&quot;&#x27;</span> + prompt + <span class="string">&#x27;&quot;, response:&quot;&#x27;</span> + <span class="built_in">repr</span>(response) + <span class="string">&#x27;&quot;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(log)  <span class="comment"># 打印日志</span></span><br><span class="line">    torch_gc()  <span class="comment"># 执行GPU内存清理</span></span><br><span class="line">    <span class="keyword">return</span> answer  <span class="comment"># 返回响应</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 加载预训练的分词器和模型</span></span><br><span class="line">    model_name_or_path = <span class="string">&#x27;./qwen/Qwen2-7B-Instruct&#x27;</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=<span class="literal">False</span>)</span><br><span class="line">    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=<span class="string">&quot;auto&quot;</span>, torch_dtype=torch.bfloat16)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动FastAPI应用</span></span><br><span class="line">    <span class="comment"># 用6006端口可以将autodl的端口映射到本地，从而在本地使用api</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">6006</span>, workers=<span class="number">1</span>)  <span class="comment"># 在指定端口和主机上启动应用	</span></span><br></pre></td></tr></table></figure>

<p>执行的时候可能会报错</p>
<h3 id="Errot"><a href="#Errot" class="headerlink" title="Errot"></a>Errot</h3><h4 id="AssertionError-Torch-not-compiled-with-CUDA-enabled"><a href="#AssertionError-Torch-not-compiled-with-CUDA-enabled" class="headerlink" title="AssertionError: Torch not compiled with CUDA enabled"></a>AssertionError: Torch not compiled with CUDA enabled</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/moyong1572/article/details/119438286">https://blog.csdn.net/moyong1572/article/details/119438286</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240929205938728.png" alt="image-20240929205938728"></p>
<p>False，说明当前的pytorch版本无法使用显卡，先安装cuda</p>
<ol>
<li>查看自己显卡驱动程序的版本</li>
</ol>
<p><img src="/../image/image-20240929210039119.png" alt="image-20240929210039119"></p>
<ol start="2">
<li>下载对应的cuda</li>
</ol>
<p>查看需要下载的版本：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html</a></p>
<p><img src="/../image/image-20240929210626909.png" alt="image-20240929210626909"></p>
<p>我们需要下载12.5的版本，但GA喝update有什么区别，搞不懂</p>
<p><a target="_blank" rel="noopener" href="https://wenku.csdn.net/answer/f6694262edc811ed9e3dfa163eeb3507#:~:text=%E8%80%8C%E5%9C%A8CUDA%E4%B8%AD%EF%BC%8CGA">https://wenku.csdn.net/answer/f6694262edc811ed9e3dfa163eeb3507#:~:text=%E8%80%8C%E5%9C%A8CUDA%E4%B8%AD%EF%BC%8CGA</a></p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
<p><img src="/../image/image-20240929210802209.png" alt="image-20240929210802209"></p>
<p>进入下载页面，选择对应的操作系统，中间有一步我选择local了，怕网络不好</p>
<p><img src="/../image/image-20240929210855880.png" alt="image-20240929210855880"></p>
<p>选完，这里会有对应的版本给你下载，这个下载指引挺有意思的</p>
<p><img src="/../image/image-20240929210948888.png" alt="image-20240929210948888"></p>
<p>下载好后就可以安装了：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_34409703/article/details/93226830">https://blog.csdn.net/weixin_34409703/article/details/93226830</a></p>
<p>双击安装下载的.exe文件，然后选择解压路径，如下图，解压到哪里无所谓，安装成功会自动删除；</p>
<p><img src="/../image/image-20240929211712678.png" alt="image-20240929211712678"></p>
<p><img src="/../image/image-20240929211951860.png" alt="image-20240929211951860"></p>
<p>这里我先继续试试</p>
<p><img src="/../image/image-20240929212014051.png" alt="image-20240929212014051"></p>
<p>解压完成后，得到如下图：</p>
<ul>
<li>精简：安装所有CUDA模块，并覆盖掉当前的NVIDIA驱动程序；（说实话，容易出问题）</li>
<li>自定义：选择自己想要安装的模块，此处选择这里；</li>
</ul>
<p><img src="/../image/image-20240929212028303.png" alt="image-20240929212028303"></p>
<p>下面几个模块准确具体有什么用，不能100%确定，但能大概才出来：</p>
<ul>
<li>CUDA：这个是必须的，下面有CUDA Runntime、Samples一些东西；</li>
<li>NVIDIA GeForce Experience：这个好像是为了更好的游戏体验，之前安装显卡驱动程序时也提示是否安装，果断拒绝了；</li>
<li>Other components：这里的PhysX好像也是为了游戏体验来的；</li>
<li>Driver components：这个就要慎重了，<strong>意思就是重新安装显卡驱动程序</strong>；如果之前已经成功安装驱动程序，这里就不用选了；如果之前没安装驱动程序，<strong>建议还是去官网上单独下载驱动程序进行安装吧</strong></li>
</ul>
<p>根据这个，我也是只保留了第一个选项</p>
<p><img src="/../image/image-20240929212132253.png" alt="image-20240929212132253"></p>
<p><img src="/../image/image-20240929212141125.png" alt="image-20240929212141125"></p>
<p>这里我修改到其它路径了，而且这里我只有一个选项。。。</p>
<p><img src="/../image/image-20240929212610431.png" alt="image-20240929212610431"></p>
<p>安装完成后配置一下环境变量</p>
<p>将<code>F:/Nvida/lib/x64</code>添加的系统变量的path中；</p>
<p>然后nvcc -V即可</p>
<p><img src="/../image/image-20240929213109888.png" alt="image-20240929213109888"></p>
<ol start="3">
<li>还需要安装对应的CuDNN</li>
</ol>
<p>下载网址 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-archive">https://developer.nvidia.com/rdp/cudnn-archive</a></p>
<p>下载对应CUDA版本的CuDNN</p>
<p>下载完成后，解压得到一个名为cudnn-windows-x86_64-8.9.7.29_cuda12-archive的文件夹；</p>
<blockquote>
<p>该文件夹下的文件复制到上一步安装的CUDA中；注意对应的文件夹；<br>.&#x2F;cuda&#x2F;bin&#x2F;.dll 复制到 .&#x2F;NVIDIA GPU Computing Tookit&#x2F;CUDA&#x2F;v8.0&#x2F;bin&#x2F;<br>.&#x2F;cuda&#x2F;include&#x2F;.dll 复制到 .&#x2F;NVIDIA GPU Computing Tookit&#x2F;CUDA&#x2F;v8.0&#x2F;include&#x2F;<br>.&#x2F;cuda&#x2F;lib&#x2F;x64&#x2F;**.dll 复制到 .&#x2F;NVIDIA GPU Computing Tookit&#x2F;CUDA&#x2F;v8.0&#x2F;lib&#x2F;x64&#x2F;</p>
</blockquote>
<p>这里根据实际情况来操作，cudnn就是原来的扩充，直接把对应的动态链接库dll，要包含的头文件*.h和要用的lib库，给补充到原拉的cuda中即可</p>
<p>安装好后测试Pytorch是否可以使用，运行刚刚的检查脚本，还是False&#x2F;。。。</p>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/moyong1572/article/details/119438286">https://blog.csdn.net/moyong1572/article/details/119438286</a></p>
<p>还有一种情况也会发生错误<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=Torch&spm=1001.2101.3001.7020">Torch</a> not compiled with CUDA enabled，那就是安装的pytorch是cpu版本。。。</p>
<p>访问链接：<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/locally/#supported-windows-distributions%EF%BC%8C%E9%80%89%E6%8B%A9%E7%9B%B8%E5%BA%94%E7%9A%84%E7%89%88%E6%9C%AC">https://pytorch.org/get-started/locally/#supported-windows-distributions，选择相应的版本</a></p>
<p><img src="/../image/image-20240929220037638.png" alt="image-20240929220037638"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240929220306521.png" alt="image-20240929220306521"></p>
<p>有点大啊，我看看能不能手动安装，复制下载链接，IDM+手动设置代理</p>
<p><img src="/../image/image-20240929220903447.png" alt="image-20240929220903447"></p>
<p>确实快的多，下载完放到相应的位置即可，就是大小有点对不上，他的2.5应该值得是解压后的，whl是一个压缩文件，下载好后，给他放到虚环境下的.&#x2F;qwen&#x2F;Lib&#x2F;site-packages,然后再pip一下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install F:\qwen\.qwen\lib\site-packages\torch-2.4.1+cu124-cp39-cp39-win_amd64.whl</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240929221803376.png" alt="image-20240929221803376"></p>
<h5 id="测试是否安装成功"><a href="#测试是否安装成功" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h5><p><img src="/../image/image-20240929222109947.png" alt="image-20240929222109947"></p>
<p>但还是有问题</p>
<p><img src="/../image/image-20240929224415158.png" alt="image-20240929224415158"></p>
<p>感觉靠谱i的解释如下，但这个慢点，好像慢的有点多</p>
<p><img src="/../image/image-20240929224520750.png" alt="image-20240929224520750"></p>
<p><img src="/../image/image-20240929225706044.png" alt="image-20240929225706044"></p>
<p>我试着换个版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp39-cp39-win_amd64.whl</span><br></pre></td></tr></table></figure>

<p><img src="/../image/image-20240929231604190.png" alt="image-20240929231604190"></p>
<p>这次也是挺慢的，但没有报错了</p>
<p><img src="/../image/image-20240929233328129.png" alt="image-20240929233328129"></p>
<p><img src="/../image/image-20240929225304370.png" alt="image-20240929225304370"></p>
<p>这个错误，DEVICE_ID得设置成0，<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38614074/article/details/139499410#:~:text=RuntimeErr">https://blog.csdn.net/qq_38614074/article/details/139499410#:~:text=RuntimeErr</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Youzipii</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/09/28/qwen-Fastapi/">http://example.com/2024/09/28/qwen-Fastapi/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">You_zip</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/09/26/Python%E8%99%9A%E7%8E%AF%E5%A2%83/" title="Python虚环境"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python虚环境</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2024/08/08/zZWaxXAdoB6sS8e.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Youzipii</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">83</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/youzipii"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#qwen-Fastapi%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93"><span class="toc-text">qwen+Fastapi搭建本地知识库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-text">环境准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%99%9A%E7%8E%AF%E5%A2%83"><span class="toc-text">创建虚环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96"><span class="toc-text">安装依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD"><span class="toc-text">模型下载</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%87%86%E5%A4%87"><span class="toc-text">代码准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85fastapi%E5%BA%93"><span class="toc-text">安装fastapi库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Errot"><span class="toc-text">Errot</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AssertionError-Torch-not-compiled-with-CUDA-enabled"><span class="toc-text">AssertionError: Torch not compiled with CUDA enabled</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F"><span class="toc-text">测试是否安装成功</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/28/qwen-Fastapi/" title="qwen+Fastapi">qwen+Fastapi</a><time datetime="2024-09-28T12:03:21.000Z" title="发表于 2024-09-28 20:03:21">2024-09-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/26/Python%E8%99%9A%E7%8E%AF%E5%A2%83/" title="Python虚环境">Python虚环境</a><time datetime="2024-09-26T14:00:28.000Z" title="发表于 2024-09-26 22:00:28">2024-09-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/26/Debian%E5%AE%89%E8%A3%85docker-docker-compose/" title="Debian安装docker/docker compose">Debian安装docker/docker compose</a><time datetime="2024-09-26T01:02:22.000Z" title="发表于 2024-09-26 09:02:22">2024-09-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/25/Debian%E5%AE%89%E8%A3%85python2/" title="Debian安装python2">Debian安装python2</a><time datetime="2024-09-25T14:45:08.000Z" title="发表于 2024-09-25 22:45:08">2024-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/25/Debian%E5%AE%89%E8%A3%85jdk1-8/" title="Debian安装jdk1.8">Debian安装jdk1.8</a><time datetime="2024-09-25T14:09:58.000Z" title="发表于 2024-09-25 22:09:58">2024-09-25</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/image/bk_image/bg3.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Youzipii</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>